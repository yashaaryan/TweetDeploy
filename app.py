from fastapi import FastAPI, Form
from starlette.responses import HTMLResponse
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import re
from tensorflow.keras.preprocessing.text import Tokenizer
import string
import unicodedata
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk
import torch
from transformers import BertTokenizer, BertForSequenceClassification



nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('stopwords')
nltk.download('punkt')


def remove_urls(text):
    """Remove URLs from the text."""
    url_pattern = re.compile(r'https?://\S+|www\.\S+')
    return url_pattern.sub('', text)

def remove_punctuation(text):
    """Remove punctuation from the text."""
    table = str.maketrans('', '', string.punctuation)
    return text.translate(table)

def remove_emojis(text):
    """Remove emojis from the text."""
    emoji_pattern = re.compile(
        r'['
        u'\U0001F600-\U0001F64F'  # Emoticons
        u'\U0001F300-\U0001F5FF'  # Symbols & pictographs
        u'\U0001F680-\U0001F6FF'  # Transport & map symbols
        u'\U0001F1E0-\U0001F1FF'  # Flags (iOS)
        u'\U00002702-\U000027B0'  # Miscellaneous symbols
        u'\U000024C2-\U0001F251'  # Other symbols
        ']+',
        flags=re.UNICODE
    )
    return emoji_pattern.sub('', text)

def remove_html_tags(text):
    """Remove HTML tags from the text."""
    html_pattern = re.compile(r'<.*?>|&(?:[a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')
    return html_pattern.sub('', text)

def preprocess_text(input_text):
    """Clean and preprocess the input text."""
    cleaned_text = str(input_text)
    cleaned_text = re.sub(r"\bI'm\b", "I am", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\byou're\b", "you are", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bthey're\b", "they are", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bcan't\b", "cannot", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bwon't\b", "will not", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bdon't\b", "do not", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bdoesn't\b", "does not", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bain't\b", "am not", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bwe're\b", "we are", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bit's\b", "it is", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bu\b", "you", cleaned_text, flags=re.IGNORECASE)

    cleaned_text = re.sub(r"&gt;", ">", cleaned_text)
    cleaned_text = re.sub(r"&lt;", "<", cleaned_text)
    cleaned_text = re.sub(r"&amp;", "&", cleaned_text)


    cleaned_text = re.sub(r"\bw/\b", "with", cleaned_text)  # "w/" → "with"
    cleaned_text = re.sub(r"\blmao\b", "laughing my ass off", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"<3", "love", cleaned_text)  # Corazón → "love"
    cleaned_text = re.sub(r"\bph0tos\b", "photos", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\bamirite\b", "am I right", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\btrfc\b", "traffic", cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r"\b16yr\b", "16 year", cleaned_text)

    cleaned_text = str(cleaned_text).lower()  # Convert to lowercase

    # Remove unwanted patterns
    cleaned_text = re.sub(r'\[.*?\]', '', cleaned_text)  # Remove content inside brackets
    cleaned_text = re.sub(r'https?://\S+|www\.\S+', '', cleaned_text)  # Remove URLs
    cleaned_text = re.sub(r'<.*?>+', '', cleaned_text)  # Remove HTML tags
    cleaned_text = re.sub(r'\n', ' ', cleaned_text)  # Replace newlines with spaces
    cleaned_text = re.sub(r'\w*\d\w*', '', cleaned_text)  # Remove words with numbers

    # Call additional cleaning functions
    cleaned_text = remove_urls(cleaned_text)  # Remove URLs
    cleaned_text = remove_emojis(cleaned_text)  # Remove emojis
    cleaned_text = remove_html_tags(cleaned_text)  # Remove HTML tags
    cleaned_text = remove_punctuation(cleaned_text)  # Remove punctuation

    return cleaned_text

def process_tweet_content(tweet):
    cleaned_tweet = preprocess_text(tweet)
    processed_tweet = ' '.join(lemmatizer.lemmatize(word) for word in cleaned_tweet.split() if word not in stop_words_list)

    return processed_tweet

def normalize_text(text):
    normalized_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')
    return normalized_text

def remove_specific_words(tweet):
    tweet = normalize_text(tweet)
    tweet = tweet.translate(str.maketrans('', '', string.punctuation)).lower()
    cleaned_tweet = ' '.join(word for word in tweet.split() if word not in custom_words)

    return cleaned_tweet

def tokenize_corpus(corpus):
    return tweet_tokenizer.texts_to_sequences(corpus)


def process_input_sentence(input_sentence):
    processed_sentence = process_tweet_content(input_sentence)
    processed_sentence = process_tweet_content(processed_sentence)
    #print(processed_sentence)
    processed_sentence = remove_specific_words(processed_sentence)
    #print(processed_sentence)
    tokenized_sentence = tokenize_corpus([processed_sentence])
    #print(tokenized_sentence)
    padded_sentence = pad_sequences(tokenized_sentence, maxlen=max_length, padding='post')
    #print(padded_sentence)
    return padded_sentence

def predict_with_bert(sentence):
    """Realiza la predicción usando el modelo BERT."""
    sentence = process_tweet_content(sentence)
    sentence = remove_specific_words(sentence)
    inputs = tokenizer_bert(sentence, return_tensors="pt", padding=True, truncation=True, max_length=128)

    with torch.no_grad():
        outputs = model_bert(**inputs)
        logits = outputs.logits

    predicted_class = torch.argmax(logits, dim=1).item()
    probability = torch.softmax(logits, dim=1)[0][predicted_class].item()
    return "REAL" if predicted_class == 1 else "FAKE", probability


app = FastAPI()

# Cargar el modelo LSTM previamente entrenado
model_lstm = tf.keras.models.load_model('model_LSTM23_Final.h5')

# Cargar el modelo y el tokenizador BERT
model_bert = BertForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=2)
model_bert.load_state_dict(torch.load('bert_finetuned_model3.pth', map_location=torch.device('cpu')))
tokenizer_bert = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')


# Cargar el dataset de pruebas
train_dataset = pd.read_csv("train.csv", encoding="latin-1")
test_dataset = pd.read_csv("test.csv", encoding="latin-1")

stop_words_list = stopwords.words('english')
lemmatizer = WordNetLemmatizer()  # <-- Usamos lemmatizer en lugar de stemmer



extra_stop_words = ['u', 'im', 'r']
extra_stop_words2 = [
    'u', 'im', 'r', 'ur', 'pls', 'thx',
    'b4', 'omw', 'ppl', 'msg', 'lvl',
    'sos', '911', 'help', 'asap',
    'wtf', 'omg', 'idk', 'nvm',
    'brb', 'btw', 'lmk', 'imo',
    'stay', 'safe', 'evacuate', 'fyi'
]

all_stop_words = stop_words_list + extra_stop_words + extra_stop_words2
word_stemmer = nltk.SnowballStemmer("english")


train_dataset['text_clean'] = train_dataset['text'].apply(process_tweet_content)
test_dataset['text_clean'] = test_dataset['text'].apply(process_tweet_content)

custom_words = {'im', 'u','â', 'ã', 'one', 'ã ã', 'ã ã', 'ã âª', 'ã â', 'â ã', 'â', 'âª','â', 'ã','aaa', 'rt','aa', 'ye'}

train_dataset['text_clean'] = train_dataset['text_clean'].apply(remove_specific_words)
test_dataset['text_clean'] = test_dataset['text_clean'].apply(remove_specific_words)


train_tweets = train_dataset['text_clean'].values
test_tweets = test_dataset['text_clean'].values

tweet_tokenizer = Tokenizer()
tweet_tokenizer.fit_on_texts(train_tweets)
vocabulary_size = len(tweet_tokenizer.word_index) + 1

max_length = 23
test_padded_sentences = pad_sequences(tokenize_corpus(test_tweets),maxlen=max_length,padding='post')


model = tf.keras.models.load_model('model_LSTM23_Final.h5')

pred_probs2 = model.predict(test_padded_sentences)
preds2 = (pred_probs2 >= 0.6).astype(int)  # Umbral en 0.5

# Contar los valores de 'REAL' y 'FAKE'
real_count = (preds2 == 1).sum()
fake_count = (preds2 == 0).sum()

# Imprimir los resultados
#print(f"REAL Tweets: {real_count}")
#print(f"FAKE Tweets: {fake_count}")


results_df = pd.DataFrame({ 'Tweet': test_dataset['text'].values,'Prediction': preds2.flatten(),  # Asegurar que la predicción sea unidimensional
'Label': ['REAL' if pred == 1 else 'FAKE' for pred in preds2.flatten()]
})

#print(results_df)#Esta no quiero que se muestre.


#Primera tabla con 10 resultados del test dataset para mostrar, real tweet
real_tweets = results_df[results_df['Label'] == 'REAL'].head(10)
print(real_tweets)


#Segunda tabla con 10 resultados del test dataset para mostrar, fake tweet
fake_tweets = results_df[results_df['Label'] == 'FAKE'].tail(10)
print(fake_tweets)



# Generar tablas de tweets reales y falsos
@app.get("/", response_class=HTMLResponse)
async def main_page():
    return '''
    <html>
        <head>
            <title>Disaster Tweets</title>
            <style>
                body { font-family: Arial, sans-serif; background-color: #f0f2f5; }
                h1, h2 { text-align: center; color: #333; }
                .content { max-width: 800px; margin: auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
                input[type="text"] { width: 100%; padding: 10px; margin: 8px 0; border: 1px solid #ccc; border-radius: 4px; }
                button { background-color: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; }
                button:hover { background-color: #0056b3; }
            </style>
        </head>
        <body>
            <div class="content">
                <h1>Disaster Tweets</h1>
                <h2>Enter a tweet to predict if it is REAL or FAKE</h2>
                <form action="/predict" method="post">
                    <input type="text" name="text" placeholder="Enter the text of the tweet" maxlength="280" required/>
                    <div style="text-align: center;">
                        <button type="submit" name="model_type" value="lstm">Predict LSTM</button>
                        <button type="submit" name="model_type" value="bert">Predict BERT</button>
                    </div>
                </form>
            </div>
        </body>
    </html>
    '''

@app.post('/predict', response_class=HTMLResponse)
async def predict(text: str = Form(...), model_type: str = Form(...)):
    # Ejecutar predicción con el modelo seleccionado
    if model_type == "lstm":
        # Preprocesar y predecir con el modelo LSTM
        processed_text = process_input_sentence(text)
        prediction = model_lstm.predict(processed_text)
        prediction_label = "REAL" if prediction >= 0.6 else "FAKE"
        probability = prediction[0][0] if prediction >= 0.6 else 1 - prediction[0][0]
    else:
        # Predecir con el modelo BERT
        prediction_label, probability = predict_with_bert(text)
    
    # Generar respuesta HTML con el resultado de la predicción
    return f"""
    <html>
        <head>
            <title>Prediction Result</title>
            <style>
                /* Estilos para dar formato al resultado */
                body {{
                    font-family: Arial, sans-serif;
                    display: flex;
                    justify-content: center;
                    align-items: center;
                    height: 100vh;
                    margin: 0;
                    background-color: #f2f2f2;
                }}
                .content {{
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                    width: 80%;
                    max-width: 600px;
                    text-align: center;
                }}
                h2 {{
                    color: #333;
                    font-size: 24px;
                    margin-bottom: 10px;
                }}
                p {{
                    font-size: 18px;
                    color: #555;
                    margin: 5px 0;
                }}
                button {{
                    padding: 10px 20px;
                    background-color: #4CAF50;
                    color: #fff;
                    border: none;
                    border-radius: 5px;
                    font-size: 16px;
                    cursor: pointer;
                    margin-top: 15px;
                }}
                button:hover {{
                    background-color: #45a049;
                }}
            </style>
        </head>
        <body>
            <div class="content">
                <h2>Prediction Result</h2>
                <p><strong>Tweet:</strong> {text}</p>
                <p><strong>Prediction:</strong> {prediction_label} (Probability: {probability:.2f})</p>
                <form action="/" method="get">
                    <button type="submit">Back</button>
                </form>
            </div>
        </body>
    </html>
    """

